{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.12"},"papermill":{"default_parameters":{},"duration":170.878821,"end_time":"2023-04-08T19:36:57.176275","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2023-04-08T19:34:06.297454","version":"2.4.0"}},"nbformat_minor":5,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Import Libraries","metadata":{"papermill":{"duration":0.006974,"end_time":"2023-04-08T19:34:15.177973","exception":false,"start_time":"2023-04-08T19:34:15.170999","status":"completed"},"tags":[]}},{"cell_type":"code","source":"!pip install keras-cv-attention-models","metadata":{"papermill":{"duration":20.490093,"end_time":"2023-04-08T19:34:35.675214","exception":false,"start_time":"2023-04-08T19:34:15.185121","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-04-12T16:01:51.353953Z","iopub.execute_input":"2023-04-12T16:01:51.354531Z","iopub.status.idle":"2023-04-12T16:02:12.443565Z","shell.execute_reply.started":"2023-04-12T16:01:51.354442Z","shell.execute_reply":"2023-04-12T16:02:12.442279Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Collecting keras-cv-attention-models\n  Downloading keras_cv_attention_models-1.3.13-py3-none-any.whl (618 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m618.3/618.3 kB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: tensorflow in /opt/conda/lib/python3.7/site-packages (from keras-cv-attention-models) (2.11.0)\nRequirement already satisfied: tensorflow-datasets in /opt/conda/lib/python3.7/site-packages (from keras-cv-attention-models) (4.8.2)\nRequirement already satisfied: tensorflow-addons in /opt/conda/lib/python3.7/site-packages (from keras-cv-attention-models) (0.19.0)\nRequirement already satisfied: absl-py>=1.0.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow->keras-cv-attention-models) (1.4.0)\nRequirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /opt/conda/lib/python3.7/site-packages (from tensorflow->keras-cv-attention-models) (0.29.0)\nRequirement already satisfied: keras<2.12,>=2.11.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow->keras-cv-attention-models) (2.11.0)\nRequirement already satisfied: six>=1.12.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow->keras-cv-attention-models) (1.16.0)\nRequirement already satisfied: typing-extensions>=3.6.6 in /opt/conda/lib/python3.7/site-packages (from tensorflow->keras-cv-attention-models) (4.4.0)\nRequirement already satisfied: numpy>=1.20 in /opt/conda/lib/python3.7/site-packages (from tensorflow->keras-cv-attention-models) (1.21.6)\nRequirement already satisfied: gast<=0.4.0,>=0.2.1 in /opt/conda/lib/python3.7/site-packages (from tensorflow->keras-cv-attention-models) (0.4.0)\nRequirement already satisfied: tensorboard<2.12,>=2.11 in /opt/conda/lib/python3.7/site-packages (from tensorflow->keras-cv-attention-models) (2.11.2)\nRequirement already satisfied: opt-einsum>=2.3.2 in /opt/conda/lib/python3.7/site-packages (from tensorflow->keras-cv-attention-models) (3.3.0)\nCollecting protobuf<3.20,>=3.9.2\n  Downloading protobuf-3.19.6-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m44.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: libclang>=13.0.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow->keras-cv-attention-models) (15.0.6.1)\nRequirement already satisfied: flatbuffers>=2.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow->keras-cv-attention-models) (23.1.21)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.7/site-packages (from tensorflow->keras-cv-attention-models) (23.0)\nRequirement already satisfied: wrapt>=1.11.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow->keras-cv-attention-models) (1.14.1)\nRequirement already satisfied: termcolor>=1.1.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow->keras-cv-attention-models) (2.2.0)\nRequirement already satisfied: grpcio<2.0,>=1.24.3 in /opt/conda/lib/python3.7/site-packages (from tensorflow->keras-cv-attention-models) (1.51.1)\nRequirement already satisfied: tensorflow-estimator<2.12,>=2.11.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow->keras-cv-attention-models) (2.11.0)\nRequirement already satisfied: h5py>=2.9.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow->keras-cv-attention-models) (3.8.0)\nRequirement already satisfied: astunparse>=1.6.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow->keras-cv-attention-models) (1.6.3)\nRequirement already satisfied: google-pasta>=0.1.1 in /opt/conda/lib/python3.7/site-packages (from tensorflow->keras-cv-attention-models) (0.2.0)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.7/site-packages (from tensorflow->keras-cv-attention-models) (59.8.0)\nRequirement already satisfied: typeguard>=2.7 in /opt/conda/lib/python3.7/site-packages (from tensorflow-addons->keras-cv-attention-models) (2.13.3)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.7/site-packages (from tensorflow-datasets->keras-cv-attention-models) (4.64.1)\nRequirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow-datasets->keras-cv-attention-models) (2.28.2)\nRequirement already satisfied: tensorflow-metadata in /opt/conda/lib/python3.7/site-packages (from tensorflow-datasets->keras-cv-attention-models) (1.12.0)\nRequirement already satisfied: toml in /opt/conda/lib/python3.7/site-packages (from tensorflow-datasets->keras-cv-attention-models) (0.10.2)\nRequirement already satisfied: dm-tree in /opt/conda/lib/python3.7/site-packages (from tensorflow-datasets->keras-cv-attention-models) (0.1.8)\nRequirement already satisfied: etils[enp,epath]>=0.9.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow-datasets->keras-cv-attention-models) (0.9.0)\nRequirement already satisfied: click in /opt/conda/lib/python3.7/site-packages (from tensorflow-datasets->keras-cv-attention-models) (8.1.3)\nRequirement already satisfied: importlib-resources in /opt/conda/lib/python3.7/site-packages (from tensorflow-datasets->keras-cv-attention-models) (5.10.2)\nRequirement already satisfied: promise in /opt/conda/lib/python3.7/site-packages (from tensorflow-datasets->keras-cv-attention-models) (2.3)\nRequirement already satisfied: psutil in /opt/conda/lib/python3.7/site-packages (from tensorflow-datasets->keras-cv-attention-models) (5.9.3)\nRequirement already satisfied: dill in /opt/conda/lib/python3.7/site-packages (from tensorflow-datasets->keras-cv-attention-models) (0.3.6)\nRequirement already satisfied: wheel<1.0,>=0.23.0 in /opt/conda/lib/python3.7/site-packages (from astunparse>=1.6.0->tensorflow->keras-cv-attention-models) (0.38.4)\nRequirement already satisfied: zipp in /opt/conda/lib/python3.7/site-packages (from etils[enp,epath]>=0.9.0->tensorflow-datasets->keras-cv-attention-models) (3.11.0)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests>=2.19.0->tensorflow-datasets->keras-cv-attention-models) (2022.12.7)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests>=2.19.0->tensorflow-datasets->keras-cv-attention-models) (3.4)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests>=2.19.0->tensorflow-datasets->keras-cv-attention-models) (1.26.14)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.7/site-packages (from requests>=2.19.0->tensorflow-datasets->keras-cv-attention-models) (2.1.1)\nRequirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /opt/conda/lib/python3.7/site-packages (from tensorboard<2.12,>=2.11->tensorflow->keras-cv-attention-models) (0.4.6)\nRequirement already satisfied: google-auth<3,>=1.6.3 in /opt/conda/lib/python3.7/site-packages (from tensorboard<2.12,>=2.11->tensorflow->keras-cv-attention-models) (1.35.0)\nRequirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.7/site-packages (from tensorboard<2.12,>=2.11->tensorflow->keras-cv-attention-models) (3.4.1)\nRequirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard<2.12,>=2.11->tensorflow->keras-cv-attention-models) (0.6.1)\nRequirement already satisfied: werkzeug>=1.0.1 in /opt/conda/lib/python3.7/site-packages (from tensorboard<2.12,>=2.11->tensorflow->keras-cv-attention-models) (2.2.3)\nRequirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard<2.12,>=2.11->tensorflow->keras-cv-attention-models) (1.8.1)\nRequirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from click->tensorflow-datasets->keras-cv-attention-models) (4.11.4)\nRequirement already satisfied: googleapis-common-protos<2,>=1.52.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow-metadata->tensorflow-datasets->keras-cv-attention-models) (1.58.0)\nRequirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.7/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow->keras-cv-attention-models) (0.2.8)\nRequirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.7/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow->keras-cv-attention-models) (4.9)\nRequirement already satisfied: cachetools<5.0,>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow->keras-cv-attention-models) (4.2.4)\nRequirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.7/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow->keras-cv-attention-models) (1.3.1)\nRequirement already satisfied: MarkupSafe>=2.1.1 in /opt/conda/lib/python3.7/site-packages (from werkzeug>=1.0.1->tensorboard<2.12,>=2.11->tensorflow->keras-cv-attention-models) (2.1.1)\nRequirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/conda/lib/python3.7/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow->keras-cv-attention-models) (0.4.8)\nRequirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.7/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow->keras-cv-attention-models) (3.2.2)\nInstalling collected packages: protobuf, keras-cv-attention-models\n  Attempting uninstall: protobuf\n    Found existing installation: protobuf 3.20.3\n    Uninstalling protobuf-3.20.3:\n      Successfully uninstalled protobuf-3.20.3\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ncudf 21.12.2 requires cupy-cuda115, which is not installed.\ntfx-bsl 1.12.0 requires google-api-python-client<2,>=1.7.11, but you have google-api-python-client 2.83.0 which is incompatible.\ntfx-bsl 1.12.0 requires pyarrow<7,>=6, but you have pyarrow 5.0.0 which is incompatible.\ntensorflow-transform 1.12.0 requires pyarrow<7,>=6, but you have pyarrow 5.0.0 which is incompatible.\nonnx 1.13.1 requires protobuf<4,>=3.20.2, but you have protobuf 3.19.6 which is incompatible.\napache-beam 2.44.0 requires dill<0.3.2,>=0.3.1.1, but you have dill 0.3.6 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed keras-cv-attention-models-1.3.13 protobuf-3.19.6\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport tensorflow as tf\nimport tensorflow_addons as tfa\nimport matplotlib.pyplot as plt\nimport matplotlib as mpl\n\nfrom tqdm.notebook import tqdm\nfrom multiprocessing import cpu_count\nfrom kaggle_datasets import KaggleDatasets\nfrom sklearn.model_selection import train_test_split\nfrom keras_cv_attention_models import convnext\n\n\nimport numpy as np\nimport os\nimport PIL\nimport PIL.Image\nimport tensorflow as tf\nimport tensorflow_datasets as tfds\n\nimport os\nimport time\nimport pickle\nimport math\nimport random\nimport sys\nimport cv2\nimport gc\nimport datetime\n\nprint(f'Tensorflow Version: {tf.__version__}')\nprint(f'Python Version: {sys.version}')","metadata":{"papermill":{"duration":8.143908,"end_time":"2023-04-08T19:34:43.829436","exception":false,"start_time":"2023-04-08T19:34:35.685528","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-04-12T16:02:12.446930Z","iopub.execute_input":"2023-04-12T16:02:12.447815Z","iopub.status.idle":"2023-04-12T16:02:19.685912Z","shell.execute_reply.started":"2023-04-12T16:02:12.447777Z","shell.execute_reply":"2023-04-12T16:02:19.683825Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Tensorflow Version: 2.11.0\nPython Version: 3.7.12 | packaged by conda-forge | (default, Oct 26 2021, 06:08:53) \n[GCC 9.4.0]\n","output_type":"stream"}]},{"cell_type":"code","source":"now = datetime.datetime.now().strftime(\"%d-%b-%Y %H-%M-%S\")\nnp.save(now, np.array([now]))","metadata":{"papermill":{"duration":0.01765,"end_time":"2023-04-08T19:34:43.855855","exception":false,"start_time":"2023-04-08T19:34:43.838205","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-04-12T16:02:19.688232Z","iopub.execute_input":"2023-04-12T16:02:19.689404Z","iopub.status.idle":"2023-04-12T16:02:19.695078Z","shell.execute_reply.started":"2023-04-12T16:02:19.689359Z","shell.execute_reply":"2023-04-12T16:02:19.693967Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"## MP policy","metadata":{"papermill":{"duration":0.008072,"end_time":"2023-04-08T19:34:43.872368","exception":false,"start_time":"2023-04-08T19:34:43.864296","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# # float32 or mixed_float16 (mixed precision: compute float16, variable float32)\n# # TPU is fast enough and has enough memory to use float32\n# policy = tf.keras.mixed_precision.Policy('float32')\n# tf.keras.mixed_precision.set_global_policy(policy)\n\n# print(f'Compute dtype: {tf.keras.mixed_precision.global_policy().compute_dtype}')\n# print(f'Variable dtype: {tf.keras.mixed_precision.global_policy().variable_dtype}')","metadata":{"papermill":{"duration":0.015897,"end_time":"2023-04-08T19:34:43.896935","exception":false,"start_time":"2023-04-08T19:34:43.881038","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-04-12T16:02:19.700710Z","iopub.execute_input":"2023-04-12T16:02:19.702029Z","iopub.status.idle":"2023-04-12T16:02:19.716842Z","shell.execute_reply.started":"2023-04-12T16:02:19.701982Z","shell.execute_reply":"2023-04-12T16:02:19.715499Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"## Matplotlib Config¶\n","metadata":{"papermill":{"duration":0.008167,"end_time":"2023-04-08T19:34:43.913549","exception":false,"start_time":"2023-04-08T19:34:43.905382","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# MatplotLib Global Settings\nmpl.rcParams.update(mpl.rcParamsDefault)\nmpl.rcParams['xtick.labelsize'] = 16\nmpl.rcParams['ytick.labelsize'] = 16\nmpl.rcParams['axes.labelsize'] = 18\nmpl.rcParams['axes.titlesize'] = 24","metadata":{"papermill":{"duration":0.017978,"end_time":"2023-04-08T19:34:43.939810","exception":false,"start_time":"2023-04-08T19:34:43.921832","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-04-12T16:02:19.718670Z","iopub.execute_input":"2023-04-12T16:02:19.719176Z","iopub.status.idle":"2023-04-12T16:02:19.728171Z","shell.execute_reply.started":"2023-04-12T16:02:19.719132Z","shell.execute_reply":"2023-04-12T16:02:19.727111Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"## Config","metadata":{"papermill":{"duration":0.00798,"end_time":"2023-04-08T19:34:43.955981","exception":false,"start_time":"2023-04-08T19:34:43.948001","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# gpu_devices = tf.config.experimental.list_physical_devices('GPU')\n# for device in gpu_devices:\n#     tf.config.experimental.set_memory_growth(device, True)","metadata":{"papermill":{"duration":0.015647,"end_time":"2023-04-08T19:34:43.979786","exception":false,"start_time":"2023-04-08T19:34:43.964139","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-04-12T16:02:19.730173Z","iopub.execute_input":"2023-04-12T16:02:19.730601Z","iopub.status.idle":"2023-04-12T16:02:19.737096Z","shell.execute_reply.started":"2023-04-12T16:02:19.730559Z","shell.execute_reply":"2023-04-12T16:02:19.735661Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"## Load Data","metadata":{"papermill":{"duration":0.00804,"end_time":"2023-04-08T19:34:43.996038","exception":false,"start_time":"2023-04-08T19:34:43.987998","status":"completed"},"tags":[]}},{"cell_type":"code","source":"test_ds = tf.keras.utils.image_dataset_from_directory(\n  '/kaggle/input/fake-images-detecttion-datasettest-task1/Test_Dataset/test-task1',\n  seed=0,\n  image_size=(224, 224),\n  batch_size=8,\n  labels=None,\n  shuffle=False)","metadata":{"papermill":{"duration":14.317228,"end_time":"2023-04-08T19:34:58.321552","exception":false,"start_time":"2023-04-08T19:34:44.004324","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-04-12T16:02:19.739190Z","iopub.execute_input":"2023-04-12T16:02:19.739759Z","iopub.status.idle":"2023-04-12T16:02:35.799907Z","shell.execute_reply.started":"2023-04-12T16:02:19.739719Z","shell.execute_reply":"2023-04-12T16:02:35.798873Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"Found 7000 files belonging to 1 classes.\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Model","metadata":{"papermill":{"duration":0.00814,"end_time":"2023-04-08T19:34:58.338444","exception":false,"start_time":"2023-04-08T19:34:58.330304","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# Seed all random number generators\ndef seed_everything(seed=0):\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    random.seed(seed)\n    np.random.seed(seed)\n    tf.random.set_seed(seed)\n\nseed_everything()\n","metadata":{"papermill":{"duration":0.018043,"end_time":"2023-04-08T19:34:58.365177","exception":false,"start_time":"2023-04-08T19:34:58.347134","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-04-12T16:02:35.803162Z","iopub.execute_input":"2023-04-12T16:02:35.803828Z","iopub.status.idle":"2023-04-12T16:02:35.809904Z","shell.execute_reply.started":"2023-04-12T16:02:35.803787Z","shell.execute_reply":"2023-04-12T16:02:35.808797Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"def normalize(image):\n#     # Repeat channels to create 3 channel images required by pretrained ConvNextV2 models\n#     image = tf.repeat(image, repeats=3, axis=3)\n    # Cast to float 32\n    image = tf.cast(image, tf.float32)\n    # Normalize with respect to ImageNet mean/std\n    image = tf.keras.applications.imagenet_utils.preprocess_input(image, mode='torch')\n\n    return image","metadata":{"papermill":{"duration":0.016824,"end_time":"2023-04-08T19:34:58.390354","exception":false,"start_time":"2023-04-08T19:34:58.373530","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-04-12T16:02:35.811715Z","iopub.execute_input":"2023-04-12T16:02:35.812391Z","iopub.status.idle":"2023-04-12T16:02:35.823724Z","shell.execute_reply.started":"2023-04-12T16:02:35.812328Z","shell.execute_reply":"2023-04-12T16:02:35.822583Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"STRATEGY = tf.distribute.MirroredStrategy() # default distribution strategy in Tensorflow. Works on CPU and single GPU.\n\nN_REPLICAS = STRATEGY.num_replicas_in_sync","metadata":{"papermill":{"duration":0.026039,"end_time":"2023-04-08T19:34:58.424623","exception":false,"start_time":"2023-04-08T19:34:58.398584","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-04-12T16:02:35.829470Z","iopub.execute_input":"2023-04-12T16:02:35.829849Z","iopub.status.idle":"2023-04-12T16:02:36.149420Z","shell.execute_reply.started":"2023-04-12T16:02:35.829812Z","shell.execute_reply":"2023-04-12T16:02:36.148140Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"N_REPLICAS","metadata":{"papermill":{"duration":0.018228,"end_time":"2023-04-08T19:34:58.451347","exception":false,"start_time":"2023-04-08T19:34:58.433119","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-04-12T16:02:36.151302Z","iopub.execute_input":"2023-04-12T16:02:36.152018Z","iopub.status.idle":"2023-04-12T16:02:36.160965Z","shell.execute_reply.started":"2023-04-12T16:02:36.151977Z","shell.execute_reply":"2023-04-12T16:02:36.159296Z"},"trusted":true},"execution_count":12,"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"2"},"metadata":{}}]},{"cell_type":"code","source":"from keras_cv_attention_models import volo","metadata":{"papermill":{"duration":0.015764,"end_time":"2023-04-08T19:34:58.476090","exception":false,"start_time":"2023-04-08T19:34:58.460326","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-04-12T16:02:36.163084Z","iopub.execute_input":"2023-04-12T16:02:36.163865Z","iopub.status.idle":"2023-04-12T16:02:36.169638Z","shell.execute_reply.started":"2023-04-12T16:02:36.163825Z","shell.execute_reply":"2023-04-12T16:02:36.168388Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"def get_model(path):\n    # Inputs, note the names are equal to the dictionary keys in the dataset\n    image = tf.keras.layers.Input((224, 224, 3), name='image', dtype=tf.uint8)\n\n    # Normalize Input\n    image_norm = normalize(image)\n\n    # CNN Prediction in range [0,1]\n    x = volo.VOLO_d2(\n        input_shape=(224, 224, 3),\n        pretrained='imagenet',\n        num_classes=0,\n    )(image_norm)\n\n    # Average Pooling BxHxWxC -> BxC\n    x = tf.keras.layers.GlobalAveragePooling2D()(x)\n    # Dropout to prevent Overfitting\n    x = tf.keras.layers.Dropout(0.1)(x)\n    # Output value between [0, 1] using Sigmoid function\n    outputs = tf.keras.layers.Dense(1, activation='sigmoid')(x)\n\n    # Define model with inputs and outputs\n    model = tf.keras.models.Model(inputs=image, outputs=outputs)\n\n    # Load pretrained Model Weights\n    model.load_weights(path)\n\n    # Set model non-trainable\n    model.trainable = False\n\n    # Compile model\n    model.compile()\n\n    return model","metadata":{"papermill":{"duration":0.019082,"end_time":"2023-04-08T19:34:58.503558","exception":false,"start_time":"2023-04-08T19:34:58.484476","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-04-12T16:02:36.171917Z","iopub.execute_input":"2023-04-12T16:02:36.172805Z","iopub.status.idle":"2023-04-12T16:02:36.184231Z","shell.execute_reply.started":"2023-04-12T16:02:36.172762Z","shell.execute_reply":"2023-04-12T16:02:36.182882Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"#model = get_model('/kaggle/input/omdena_deepfake_detection_transferLearning/model.h5')\nfrom tensorflow import keras\nmodel = get_model(\"/kaggle/input/volo-model/model.h5\")\n    ","metadata":{"papermill":{"duration":7.919651,"end_time":"2023-04-08T19:35:06.431709","exception":false,"start_time":"2023-04-08T19:34:58.512058","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-04-12T16:02:36.186675Z","iopub.execute_input":"2023-04-12T16:02:36.187631Z","iopub.status.idle":"2023-04-12T16:02:48.179517Z","shell.execute_reply.started":"2023-04-12T16:02:36.187571Z","shell.execute_reply":"2023-04-12T16:02:48.178434Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"Downloading data from https://github.com/leondgarse/keras_cv_attention_models/releases/download/volo/volo_d2_224_imagenet.h5\n235718752/235718752 [==============================] - 2s 0us/step\n>>>> Load pretrained from: /root/.keras/models/volo_d2_224_imagenet.h5\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Test","metadata":{"papermill":{"duration":0.01191,"end_time":"2023-04-08T19:35:06.456718","exception":false,"start_time":"2023-04-08T19:35:06.444808","status":"completed"},"tags":[]}},{"cell_type":"code","source":"y_true=[]\nwith open('/kaggle/input/fake-images-detecttion-datasettest-task1/Test_Dataset/labels.txt') as f:\n    labels = f.readlines()\n# for line in lines:\n#     splitted_line=line.split(' ')\n#     y_true.append(int(splitted_line[1].strip('\\n')))\n    \n    ","metadata":{"papermill":{"duration":0.023002,"end_time":"2023-04-08T19:35:06.490415","exception":false,"start_time":"2023-04-08T19:35:06.467413","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-04-12T16:02:48.181111Z","iopub.execute_input":"2023-04-12T16:02:48.181480Z","iopub.status.idle":"2023-04-12T16:02:48.194814Z","shell.execute_reply.started":"2023-04-12T16:02:48.181437Z","shell.execute_reply":"2023-04-12T16:02:48.193604Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"import glob\nimage_path = glob.glob('/kaggle/input/fake-images-detecttion-datasettest-task1/Test_Dataset/test-task1/*jpg')","metadata":{"papermill":{"duration":0.036806,"end_time":"2023-04-08T19:35:06.537630","exception":false,"start_time":"2023-04-08T19:35:06.500824","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-04-12T16:02:48.197053Z","iopub.execute_input":"2023-04-12T16:02:48.197550Z","iopub.status.idle":"2023-04-12T16:02:48.226891Z","shell.execute_reply.started":"2023-04-12T16:02:48.197506Z","shell.execute_reply":"2023-04-12T16:02:48.225867Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"parh_len=len('/kaggle/input/fake-images-detecttion-datasettest-task1/Test_Dataset/test-task1/')\n","metadata":{"papermill":{"duration":0.018545,"end_time":"2023-04-08T19:35:06.566682","exception":false,"start_time":"2023-04-08T19:35:06.548137","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-04-12T16:02:48.228582Z","iopub.execute_input":"2023-04-12T16:02:48.228979Z","iopub.status.idle":"2023-04-12T16:02:48.234126Z","shell.execute_reply.started":"2023-04-12T16:02:48.228940Z","shell.execute_reply":"2023-04-12T16:02:48.232843Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"import cv2","metadata":{"papermill":{"duration":0.01731,"end_time":"2023-04-08T19:35:06.594235","exception":false,"start_time":"2023-04-08T19:35:06.576925","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-04-12T16:02:48.236127Z","iopub.execute_input":"2023-04-12T16:02:48.236984Z","iopub.status.idle":"2023-04-12T16:02:48.245240Z","shell.execute_reply.started":"2023-04-12T16:02:48.236941Z","shell.execute_reply":"2023-04-12T16:02:48.243947Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"y_true = []  # store true labels\nimages_to_predict=[]\n\n# iterate over the dataset\nfor img_path in image_path: \n    temp=img_path[parh_len:].split(\".\")\n    if (int(temp[0]) <= len(labels)):\n        y_true.append(int(labels[int(temp[0])]))\n    \n    img = cv2.imread(img_path)\n    img  = cv2.resize(img, (224, 224))\n    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n    images_to_predict.append(img)\n","metadata":{"papermill":{"duration":61.287309,"end_time":"2023-04-08T19:36:07.892215","exception":false,"start_time":"2023-04-08T19:35:06.604906","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-04-12T16:02:48.248591Z","iopub.execute_input":"2023-04-12T16:02:48.249415Z","iopub.status.idle":"2023-04-12T16:03:55.010173Z","shell.execute_reply.started":"2023-04-12T16:02:48.249383Z","shell.execute_reply":"2023-04-12T16:03:55.008996Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"images_to_predict = np.array(images_to_predict)\ny_true = np.array(y_true)","metadata":{"papermill":{"duration":0.18657,"end_time":"2023-04-08T19:36:08.090296","exception":false,"start_time":"2023-04-08T19:36:07.903726","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-04-12T16:03:55.011538Z","iopub.execute_input":"2023-04-12T16:03:55.012153Z","iopub.status.idle":"2023-04-12T16:03:55.370519Z","shell.execute_reply.started":"2023-04-12T16:03:55.012104Z","shell.execute_reply":"2023-04-12T16:03:55.369234Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"images_to_predict.shape","metadata":{"papermill":{"duration":0.020816,"end_time":"2023-04-08T19:36:08.143986","exception":false,"start_time":"2023-04-08T19:36:08.123170","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-04-12T16:03:55.371805Z","iopub.execute_input":"2023-04-12T16:03:55.372430Z","iopub.status.idle":"2023-04-12T16:03:55.384548Z","shell.execute_reply.started":"2023-04-12T16:03:55.372389Z","shell.execute_reply":"2023-04-12T16:03:55.382658Z"},"trusted":true},"execution_count":22,"outputs":[{"execution_count":22,"output_type":"execute_result","data":{"text/plain":"(7000, 224, 224, 3)"},"metadata":{}}]},{"cell_type":"code","source":"y_true.shape","metadata":{"papermill":{"duration":0.020987,"end_time":"2023-04-08T19:36:08.175993","exception":false,"start_time":"2023-04-08T19:36:08.155006","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-04-12T16:03:55.388237Z","iopub.execute_input":"2023-04-12T16:03:55.390565Z","iopub.status.idle":"2023-04-12T16:03:55.402464Z","shell.execute_reply.started":"2023-04-12T16:03:55.390527Z","shell.execute_reply":"2023-04-12T16:03:55.401157Z"},"trusted":true},"execution_count":23,"outputs":[{"execution_count":23,"output_type":"execute_result","data":{"text/plain":"(7000,)"},"metadata":{}}]},{"cell_type":"code","source":"predicted_labels = model.predict(images_to_predict)","metadata":{"papermill":{"duration":44.205812,"end_time":"2023-04-08T19:36:52.392476","exception":false,"start_time":"2023-04-08T19:36:08.186664","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-04-12T16:03:55.404238Z","iopub.execute_input":"2023-04-12T16:03:55.405390Z","iopub.status.idle":"2023-04-12T16:06:13.692438Z","shell.execute_reply.started":"2023-04-12T16:03:55.405350Z","shell.execute_reply":"2023-04-12T16:06:13.691338Z"},"trusted":true},"execution_count":24,"outputs":[{"name":"stdout","text":"219/219 [==============================] - 136s 575ms/step\n","output_type":"stream"}]},{"cell_type":"code","source":"predicted_labels[predicted_labels<0.5]=0\npredicted_labels[predicted_labels>=0.5]=1","metadata":{"papermill":{"duration":0.030127,"end_time":"2023-04-08T19:36:52.444948","exception":false,"start_time":"2023-04-08T19:36:52.414821","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-04-12T16:06:13.693929Z","iopub.execute_input":"2023-04-12T16:06:13.694327Z","iopub.status.idle":"2023-04-12T16:06:13.701968Z","shell.execute_reply.started":"2023-04-12T16:06:13.694278Z","shell.execute_reply":"2023-04-12T16:06:13.700643Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns\n","metadata":{"papermill":{"duration":0.447968,"end_time":"2023-04-08T19:36:52.914444","exception":false,"start_time":"2023-04-08T19:36:52.466476","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-04-12T16:06:13.703978Z","iopub.execute_input":"2023-04-12T16:06:13.705034Z","iopub.status.idle":"2023-04-12T16:06:13.877130Z","shell.execute_reply.started":"2023-04-12T16:06:13.704972Z","shell.execute_reply":"2023-04-12T16:06:13.876092Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"# original test set labels (0 if the image is real; 1 if the image is Deepfake), However here we have it inverted","metadata":{"papermill":{"duration":0.029642,"end_time":"2023-04-08T19:36:52.966661","exception":false,"start_time":"2023-04-08T19:36:52.937019","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-04-12T16:06:13.878610Z","iopub.execute_input":"2023-04-12T16:06:13.879660Z","iopub.status.idle":"2023-04-12T16:06:13.886350Z","shell.execute_reply.started":"2023-04-12T16:06:13.879603Z","shell.execute_reply":"2023-04-12T16:06:13.883103Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"correct_labels = np.array(y_true)\n","metadata":{"papermill":{"duration":0.02947,"end_time":"2023-04-08T19:36:53.017613","exception":false,"start_time":"2023-04-08T19:36:52.988143","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-04-12T16:06:13.887718Z","iopub.execute_input":"2023-04-12T16:06:13.888017Z","iopub.status.idle":"2023-04-12T16:06:13.896773Z","shell.execute_reply.started":"2023-04-12T16:06:13.887989Z","shell.execute_reply":"2023-04-12T16:06:13.895052Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"correct_labels = 1- correct_labels","metadata":{"papermill":{"duration":0.029783,"end_time":"2023-04-08T19:36:53.068798","exception":false,"start_time":"2023-04-08T19:36:53.039015","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-04-12T16:06:13.903967Z","iopub.execute_input":"2023-04-12T16:06:13.904504Z","iopub.status.idle":"2023-04-12T16:06:13.909383Z","shell.execute_reply.started":"2023-04-12T16:06:13.904474Z","shell.execute_reply":"2023-04-12T16:06:13.908031Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"correct_labels.shape","metadata":{"papermill":{"duration":0.031467,"end_time":"2023-04-08T19:36:53.121635","exception":false,"start_time":"2023-04-08T19:36:53.090168","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-04-12T16:06:13.910932Z","iopub.execute_input":"2023-04-12T16:06:13.911416Z","iopub.status.idle":"2023-04-12T16:06:13.920900Z","shell.execute_reply.started":"2023-04-12T16:06:13.911367Z","shell.execute_reply":"2023-04-12T16:06:13.919619Z"},"trusted":true},"execution_count":30,"outputs":[{"execution_count":30,"output_type":"execute_result","data":{"text/plain":"(7000,)"},"metadata":{}}]},{"cell_type":"code","source":"predicted_labels.shape","metadata":{"papermill":{"duration":0.031032,"end_time":"2023-04-08T19:36:53.175005","exception":false,"start_time":"2023-04-08T19:36:53.143973","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-04-12T16:06:13.922855Z","iopub.execute_input":"2023-04-12T16:06:13.923285Z","iopub.status.idle":"2023-04-12T16:06:13.932654Z","shell.execute_reply.started":"2023-04-12T16:06:13.923248Z","shell.execute_reply":"2023-04-12T16:06:13.931225Z"},"trusted":true},"execution_count":31,"outputs":[{"execution_count":31,"output_type":"execute_result","data":{"text/plain":"(7000, 1)"},"metadata":{}}]},{"cell_type":"code","source":"from sklearn.metrics import classification_report\nprint(classification_report(correct_labels, predicted_labels.flatten()))","metadata":{"papermill":{"duration":0.045889,"end_time":"2023-04-08T19:36:53.242494","exception":false,"start_time":"2023-04-08T19:36:53.196605","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-04-12T16:06:13.934459Z","iopub.execute_input":"2023-04-12T16:06:13.935322Z","iopub.status.idle":"2023-04-12T16:06:13.960963Z","shell.execute_reply.started":"2023-04-12T16:06:13.935221Z","shell.execute_reply":"2023-04-12T16:06:13.959764Z"},"trusted":true},"execution_count":32,"outputs":[{"name":"stdout","text":"              precision    recall  f1-score   support\n\n           0       0.81      0.95      0.88      5000\n           1       0.79      0.45      0.57      2000\n\n    accuracy                           0.81      7000\n   macro avg       0.80      0.70      0.72      7000\nweighted avg       0.80      0.81      0.79      7000\n\n","output_type":"stream"}]},{"cell_type":"code","source":"# Print confusion matrix on actual test data\nfrom sklearn.metrics import confusion_matrix\n\nconfusion_matrix(correct_labels, predicted_labels.flatten())","metadata":{"execution":{"iopub.status.busy":"2023-04-12T16:06:13.962790Z","iopub.execute_input":"2023-04-12T16:06:13.963196Z","iopub.status.idle":"2023-04-12T16:06:13.975053Z","shell.execute_reply.started":"2023-04-12T16:06:13.963155Z","shell.execute_reply":"2023-04-12T16:06:13.973654Z"},"trusted":true},"execution_count":33,"outputs":[{"execution_count":33,"output_type":"execute_result","data":{"text/plain":"array([[4755,  245],\n       [1105,  895]])"},"metadata":{}}]}]}